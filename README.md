<p align="center">
  <img src="https://github.com/user-attachments/assets/a2dd997e-ad75-46b7-a76e-018b6e9e5bde" width="2000">
</p>

# ğŸ§© Project Summary  

This project demonstrates a **fully automated, end-to-end analytics and reporting platform** built on the Olist Brazilian E-commerce dataset:
- Raw CSV files are loaded into **Google BigQuery**, where **dbt (Data Build Tool)** manages a **modular, tested, and version-controlled transformation** layer of the ELT workflow â€” including **data modeling**, **testing**, **documentation**, and **analytics readiness**.
- On top of the dbt-produced marts, a **Python analytics package** performs deeper programmatic checks, anomaly detection, KPI calculations, and constructs a controlled prompt to generate **AI / LLMâ€“driven narrative reports** (generated by **OpenAI** and **Google Gemini** using validated metrics only; no raw data exposure). Finally, the generated AI narrative is embedded into **Power BI** alongside interactive dashboards.

ğŸ”— **Dataset:** The data is available on [Kaggle](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce)

# ğŸ—ï¸ Project Architecture
The key design principle of this project is **automation**: data cleaning, transformation, analytics, and report generation are fully automated, enabling fast regeneration of up-to-date dashboards and data-driven insights with minimal manual effort.  


```graphql
OLIST/
â”œâ”€ dbt-olist/                     # dbt transformation and testing
â”‚  â”œâ”€ models/
â”‚  â”œâ”€ tests/
â”‚  â””â”€ ...
â”œâ”€ python/                        # Python analytics + AI layer
â”‚  â”œâ”€ src/
â”‚  â”œâ”€ outputs/
â”‚  â””â”€ ...
â”œâ”€ README.md                      # project documentation 
â”œâ”€ .env                           # service account & API keys (excluded from GitHub)
â”œâ”€ Run_Pipeline.bat               # one-click pipeline execution
â””â”€ ...
```
 
# <img src="https://github.com/user-attachments/assets/b056cba3-26ac-4e20-bfef-64d7ab787d16" height="26" /> dbt: Data Testing & Transformation

The dbt component of this project was initially developed locally using **dbt-core** in **VS Code**, connected to **BigQuery** through a **service account key**. After completing the development, the **GitHub repository** was linked to **dbt Cloud** to execute transformations and explore the **dbt Catalog**. 


## dbt structure

```graphql
OLIST/
â”œâ”€ dbt-olist/                         # dbt transformation and testing
â”‚  â”œâ”€ analysis/
â”‚  â”œâ”€ dbt_project.yml
â”‚  â”œâ”€ profiles.yml
â”‚  â”œâ”€ models/
â”‚  â”‚  â”œâ”€ staging/                            # staging layer models
â”‚  â”‚  â”‚  â”œâ”€ _sources.yml                     # defining the sources        
â”‚  â”‚  â”‚  â”œâ”€ _staging.yml                     # defining model configs, tests, etc.
â”‚  â”‚  â”‚  â”œâ”€ STG_orders.sql
â”‚  â”‚  â”‚  â”œâ”€ ...
â”‚  â”‚  â”œâ”€ intermediate/                       # intermediate layer models
â”‚  â”‚  â”‚  â”œâ”€ INT_order_items_agg.sql
â”‚  â”‚  â”‚  â”œâ”€ ...
â”‚  â”‚  â”œâ”€ mart/                               # mart layer models
â”‚  â”‚  â”‚  â”œâ”€ _mart.yml                        # defining model configs, tests, etc.
â”‚  â”‚  â”‚  â”œâ”€ Fact_orders.sql        
â”‚  â”‚  â”‚  â”œâ”€ ...
â”‚  â”œâ”€ tests/
â”‚  â”‚  â”œâ”€ generic/
â”‚  â”‚  â”‚  â”œâ”€ not_negative.sql                 # custom generic test
â”‚  â”‚  â”œâ”€ coordinates_validation.sql          # singular test 1
â”‚  â”‚  â”œâ”€ ...
â”‚  â”œâ”€ macros/
â”‚  â”‚  â”œâ”€ schema.sql                          # macro to define schema
â”‚  â””â”€ ...
â”‚ ...
```

## âš™ï¸ Data Source Configuration  
The source datasets are defined in `_sources.yml`, referencing all raw tables located in the `rawdata` schema of the `olist-ecommerce-2025` dataset in **BigQuery**.

<p align="center"><i>Excerpt from `_sources.yml`</i></p>

``` yml
version: 2
sources:
  - name: olist_dataset
    description: "Raw tables from the Olist Brazilian E-Commerce Dataset"
    database: olist-ecommerce-2025
    schema: rawdata
    tables:
      - name: customers
        description: "Contains unique customer identifiers, their city, and state..."
      - name: geolocation
      ...
```

## ğŸ§© Modeling, Testing & Transformation Workflow  
In dbt, data transformation, testing, and documentation are tightly integrated rather than sequential. Each model, once created or updated, it is immediately tested and incorporated into the project's **Directed Acyclic Graph (DAG)**. 

<p align="center"><i>DAG of Entire Project</i></p>
<p align="center">
  <img src="https://github.com/user-attachments/assets/f44ab50e-220b-42be-a0e0-91068f7d5cdf" width="2000">
</p>


### ğŸ§± Model Layers
#### Overview
- **Staging Layer** â€“ Renaming column names, standardize datatypes, etc. 
- **Intermediate Layer** â€“ Performs joins, aggregations, and logic transformations between staging and marts.
- **Marts Layer** â€“ Produces analytics-ready tables for reporting and BI, including both **star schema** models and **standalone analytical models** such as RFM segmentation, seller performance, and delivery reliability.

A **seed** CSV enriches the models with full province names (linked by province abbreviation). Additionally, the `schema.sql` **macro** ensures schema naming consistency and automates dataset organization inside BigQuery. 

<p align="center"><i>`schema.sql`</i></p>

```
{% macro generate_schema_name(custom_schema_name, node) -%}
    {%- set default_schema = target.schema -%}
    {%- if custom_schema_name is none -%}
        {{ default_schema }}
    {%- else -%}
        {{ custom_schema_name | trim }}
    {%- endif -%}
{%- endmacro %}
```
#### A Look Into the Mart Layer
The marts layer contains both dimensional and analytical models:
- **Fact and Dimension Tables** â€“ Form the basis of a star schema, including a `date` dimension table 
- **standalone BI specific models:** Designed to answer concrete business questions and support dashboards (e.g., RFM segmentation, cohort retention, seller reliability).

  
**_Example 1: RFM Segmentation Model_**

This model segments customers using the classic **Recency, Frequency, Monetary (RFM)** framework:
- **Metrics:**
  - Recency (R): Days since last purchase
  - Frequency (F): Number of purchases
  - Monetary (M): Total spent
- **Scope:** Last 12 months of transactions in the dataset are considered
- Combined RFM score determines customer segments (*Champions*, *Loyal Customers*,*Potential Loyalists*, *At Risk*, *Lost*)

ğŸ”— **File:** [RFM Segmentation Model](https://github.com/Seyyed-Reza-Mashhadi/OLIST_Project/blob/master/dbt_olist/models/mart/BI_customer_rfm.sql)

**_Example 2: Cohort Analysis Model_**

This model groups customers into **cohorts** based on their **first purchase date** and tracks **customer retention rate** and spending across time periods. It evaluates both individual cohort performance and weighted averages to reveal overall customer lifecycle trends.

ğŸ”— **File:** [Cohort Analysis Model](https://github.com/Seyyed-Reza-Mashhadi/OLIST_Project/blob/master/dbt_olist/models/mart/BI_customer_cohorts.sql)

<p align="center"><i>Executing Cohort Analysis model build with dbt Core in VS Code</i></p>
<p align="center">
  <img src="https://github.com/user-attachments/assets/609b0059-56c7-40ac-9a29-3cadb5cff9ed" width="800">
</p>

## âœ… Integrated Data Testing
Testing occurs alongside model development â€” ensuring every transformation maintains data quality before itâ€™s used downstream.
### 1ï¸âƒ£ Generic Tests  
Generic tests ensure fundamental data integrity. Defining **unique** and **not_null** tests for primary keys is essential, while **relationships** tests validate foreign key references. For columns with a limited set of valid categorical values (e.g., `order_status`), **accepted_values** tests are applied to enforce consistency.

<p align="center"><i>Excerpt from `_staging.yml`</i></p>

```yml
version: 2
models:
- name: STG_order_payments
    description: "Order payment data with standardized data formats and column names."
    columns:
      - name: order_id
        description: "Order identifier key."
        tests:
          - not_null
          - relationships:
              arguments:
                to: ref('STG_orders')
                field: order_id
      - name: payment_value
        description: "Payment value for the order."
        tests:
          - not_null
          - not_negative
      - name: payment_type
        description: "Payment method used for the order."
        tests:
          - accepted_values:
              arguments:
                values: ['credit_card', 'boleto', 'voucher', 'debit_card', 'not_defined']
```

### 2ï¸âƒ£ Custom Generic Test  
The `not_negative` test ensures that numeric columns (e.g., `price`, `payment_value`) never contain negative values. As a **custom generic test**, it is modular and reusable across multiple models and columns.

<p align="center"><i>`not_negative.sql`</i></p>

```sql
{% test not_negative(model, column_name) %}
    SELECT {{ column_name }}
    FROM {{model}}
    WHERE {{ column_name }} < 0
{% endtest %} 
```

### 3ï¸âƒ£ Singular Tests â€“ Business Logic & Cross-Table Validation  

We implemented domain-specific singular tests to ensure business logic and data consistency. These tests highlight how **dbt enables rule-based data validation** beyond basic null checks. 

#### Example 1: Coordinates validation

- **Logic:** longitude and latitude ranges should be logical  
- **Purpose:** Ensures data reliability for future BI illustrations in maps 
- **Severity:** âŒ `error` 
- **Result:** ~0 errors â€” good data quality  
 
<p align="center"><i>`coordinates_validation.sql`</i></p>

```sql
{{ config(store_failures = true) }} 
SELECT latitude, longitude
FROM {{ ref('STG_geolocation') }}
WHERE latitude < -90 OR latitude > 90 OR longitude < -180 OR longitude > 180
LIMIT 1000  -- Cap the materialization to avoid excessive data storing in case of widespread failures
```

#### Example 2: Payment consistency

- **Logic:** For delivered/shipped/invoiced orders, aggregated payments = item price + freight  
- **Purpose:** Ensures financial completeness & accuracy  
- **Tolerance:** Â±0.05 (to avoid rounding noise)  
- **Severity:** âš ï¸ `warn`
- **Result:** ~258 mismatches were detected. Logically, this test should have an `error` severity to fail the run, but due to known data quirks (e.g., installment interest, taxes, etc.), it was set to `warn` to allow the pipeline to continue while still flagging potential issues.

<p align="center"><i>`payment_test_1.sql`</i></p>

```sql 
{{ config(severity='warn', store_failures = true) }}  

SELECT 
    p.order_id,
    p.payment_value,
    (o.total_price + o.total_freight_value) AS expected_payment
FROM {{ ref('INT_order_payments_agg') }} as p
INNER JOIN {{ ref('INT_order_items_agg') }} as o 
    ON p.order_id = o.order_id
INNER JOIN {{ ref('STG_orders') }} as s
    ON p.order_id = s.order_id
WHERE 
    s.order_status IN ('delivered', 'shipped', 'invoiced')
    AND ABS(p.payment_value - (o.total_price + o.total_freight_value)) > 0.10 -- considering a small tolerance of 10 cents
LIMIT 1000  -- Cap the materialization to avoid excessive data storing in case of widespread failures
```

## â˜ï¸ Deployment on dbt Cloud  

After completing and testing all dbt models locally using **dbt-core** in VS code, the project was deployed to **dbt Cloud**, connected directly to the GitHub repository for version control and continuous integration. The dbt Cloud environment is configured to use **Google BigQuery** as the data warehouse for computation and storage.

<p align="center"><i>`dbt_project.yml`</i></p>

```yml
name: 'olist'
version: '1.0.0'
profile: 'olist'
model-paths: ["models"]
analysis-paths: ["analyses"]
test-paths: ["tests"]
seed-paths: ["seeds"]
macro-paths: ["macros"]
snapshot-paths: ["snapshots"]
clean-targets: 
  - "target"
models:
  olist:
    staging:
      schema: staging
      +materialized: view
    intermediate:
      schema: intermediate
      +materialized: view
    mart:
      schema: mart
      +materialized: table
seeds:
  olist:
    brazil_states:
      file: seeds/brazil_states.csv
```
**Key Features in dbt Cloud:**
- **Scheduled Jobs:** Automate builds (e.g., dbt build, dbt test) on a defined cadence or trigger via CI/CD.

<p align="center">
  <img src="https://github.com/user-attachments/assets/f37f9df2-f815-4843-a604-20e9305dabeb" width="700">
</p>

- **Automatic Documentation:** dbt Cloud generates an interactive documentation site (dbt docs generate) including model descriptions, lineage graphs, and test results.

<p align="center">
  <img src="https://github.com/user-attachments/assets/47f5bcdf-5f0a-4541-88af-e42f9af8757a" width="700">
</p>

- **Data Health & Monitoring:** Built-in data quality dashboards show the latest test outcomes with intuitive green/yellow/red status icons.

<p align="center">
  <img src="https://github.com/user-attachments/assets/e3732a69-2110-4ec8-bd5b-abb1c3f138ce" width="300">
</p>

- **Interactive documentation & lineage:** **dbt Catalog** generates interactive documentation and **DAG (Directed Acyclic Graph)** visualizations, providing both data- and column-level traceability for transparency, reproducibility, and efficient debugging across the pipeline.

<p align="center">
  <img src="https://github.com/user-attachments/assets/368aeac8-0f79-41b5-a47a-fd051eca20e1" width="700">
</p>


# <img src="https://github.com/user-attachments/assets/6fd3e58f-f3ad-4957-826a-84cb7da662fc" height="26" /> Python Analytics & AI (LLM) Layer

This layer builds directly on top of **dbt-produced mart models in BigQuery** and extends the platform with programmatic analytics, anomaly detection, and **AI-assisted narrative reporting**.

## ğŸ“¦ Python package structure

```graphql
OLIST/
â”œâ”€ python/
â”‚  â”œâ”€ config/
â”‚  â”œâ”€ src/
â”‚  â”‚  â”œâ”€ __init__.py
â”‚  â”‚  â”œâ”€ utils.py                   # BigQuery connectivity & shared helpers
â”‚  â”‚  â”œâ”€ sql_queries.py                 # SQL queries referencing dbt marts
â”‚  â”‚  â”œâ”€ raw_data_qc.py             # High-level raw data QC (reporting only)
â”‚  â”‚  â”œâ”€ anomaly_detection.py       # Statistical anomaly detection
â”‚  â”‚  â”œâ”€ analysis.py                # KPI computation & analytical summaries
â”‚  â”‚  â”œâ”€ context_builder.py         # Builds LLM-safe analytical context
â”‚  â”‚  â””â”€ ai_generator.py            # Generates AI narrative reports
â”‚  â”œâ”€ scripts/
â”‚  â”‚  â”œâ”€ run_all.py                 # Pipeline orchestration
â”‚  â”œâ”€ notebooks/
â”‚  â”œâ”€ outputs/                      # JSON summaries & AI reports
â”‚  â””â”€ ...
```

## <img src="https://github.com/user-attachments/assets/6be46acc-a1c3-4b56-b0fd-f414da68f416" height="22" /> BigQuery connectivity & helpers â€” `utils.py` 

- This module centralizes authentication, client initialization, and query execution for BigQuery.
- It ensures consistent configuration and reuse across all analytics modules.

ğŸ”— Code: [utils.py](https://github.com/Seyyed-Reza-Mashhadi/OLIST_Project/blob/master/python/src/utils.py)

## <img src="https://github.com/user-attachments/assets/5a40fcd3-a093-4cc3-911e-9704ab711bef" height="22" /> Analytics SQL queries â€” `sql_queries.py`
- This is where all SQL queires (used in the python scripts for analytics) live.

ğŸ”— Code: [sql_queries.py](https://github.com/Seyyed-Reza-Mashhadi/OLIST_Project/blob/master/python/src/sql_queries.py)

## <img src="https://github.com/user-attachments/assets/ede013cf-7784-4668-97c6-c53b69009438" height="22" /> High-level QC summaries â€” `raw_data_qc.py`

- This module performs **lightweight, descriptive quality checks** on raw tables (null counts, duplicates, basic distributions) and exports the results as JSON summaries.
- **Important Notes:**
  - Enforcement of data quality rules is handled in dbt tests.
  - This Python module is intentionally limited to monitoring and reporting, not validation.

ğŸ”— Code: [raw_data_qc.py](https://github.com/Seyyed-Reza-Mashhadi/OLIST_Project/blob/master/python/src/raw_data_qc.py)

## <img src="https://github.com/user-attachments/assets/c1c6b48c-83ab-4290-b6db-5825d4e01826" height="22" /> Detection of High/Low Anomalies In Data â€” `anomaly_detection.py` 

- This module detects unusual behavior in key metrics (e.g. revenue spikes, sudden drops in order volume) using statistical techniques.
- Two complementary methods are used:
    - **IQR**-based detection for skewed distributions
    - **Z-score** detection for approximately normal distributions
- Detected anomalies are explicitly labeled, quantified, and exported as structured JSON artifacts.

ğŸ”— Code: [anomaly_detection.py](https://github.com/Seyyed-Reza-Mashhadi/OLIST_Project/blob/master/python/src/anomaly_detection.py)

## <img src="https://github.com/user-attachments/assets/b1c1f27b-14e7-444f-a612-7b3a24a47c42" height="22" /> KPI & analytical summaries â€” `analysis.py`
- This module computes core business KPIs and analytical aggregates derived from dbt marts, such as revenue and order trends, Average Order Value (AOV), seller performance and so on.
- The output is a machine-readable JSON summary, designed specifically for downstream AI consumption and auditability.

ğŸ”— Code: [analysis.py](https://github.com/Seyyed-Reza-Mashhadi/OLIST_Project/blob/master/python/src/analysis.py)

## <img src="https://github.com/user-attachments/assets/a460faaa-642a-4523-a51b-92ef63d1a1d1" height="22" /> LLM-safe context construction â€” `context_builder.py`
- This module does not call any LLMs. Its responsibility is to:
  - Merge validated JSON outputs (QC, anomalies, KPI summaries)
  - Normalize metrics and labels
  - Construct a controlled, grounded analytical context for AI consumption

ğŸ”— Code: [context_builder.py](https://github.com/Seyyed-Reza-Mashhadi/OLIST_Project/blob/master/python/src/context_builder.py)

## <img src="https://github.com/user-attachments/assets/2debcca9-4190-41e1-91b6-32643550af44" height="22" /> AI / LLM narrative generation â€” `ai_generator.py`  
- This module consumes the context produced by `context_builder.py` and generates business-facing narrative reports using **OpenAI** <img src="https://github.com/user-attachments/assets/d41cb35d-a1d5-40c5-b731-40274850d27d" height="18" /> and **Google Gemini** <img src="https://github.com/user-attachments/assets/3e8b6bb5-38a3-4b20-86d6-e25fc7e30b72" height="18" />.

- Responsible AI / LLM practices by:
  - Grounded inputs: LLMs receive only validated JSON summaries and constructed context â€” never raw tables.
  - Strict prompt constraints: Prompts explicitly prohibit assumptions or hallucinations (e.g., â€œDo NOT hallucinate or assume data that is not present. Draw careful, logical interpretations grounded strictly in the provided dataâ€
  - Determinism: Low temperature and structured prompts minimize randomness.
  - Auditability: All prompts, contexts, and AI outputs are saved to /outputs for traceability.
  - Outputs from OpenAI and Gemini are provided for coherence and factual consistency.

ğŸ”— Code: [ai_generator.py](https://github.com/Seyyed-Reza-Mashhadi/OLIST_Project/blob/master/python/src/ai_generator.py)

## <img src="https://github.com/user-attachments/assets/171fd51d-b677-4946-83ae-0baf826b2dac" height="22" /> Pipeline orchestration â€” `run_all.py`

- This script orchestrates the entire analytics and AI pipeline, and enables one-click regeneration of insights.
- A companion batch file ([Run_Pipeline.bat](https://github.com/Seyyed-Reza-Mashhadi/OLIST_Project/blob/master/Run_Pipeline.bat)) allows execution via double-click on Windows.

ğŸ”— Code: [run_all.py](https://github.com/Seyyed-Reza-Mashhadi/OLIST_Project/blob/master/python/scripts/run_all.py)

<p align="center">
  <img " src="https://github.com/user-attachments/assets/01935818-1449-404d-87ed-28e9ed72796c" width="700">
</p>


# <img src="https://github.com/user-attachments/assets/74746e0d-02d3-4d2d-951e-aad5b094ce93" height="26" /> Adding AI-generated Report to Power BI

- Import AI-augmented report to Power BI to the AI narrative page in Power BI.

<p align="center">
  <img src="https://github.com/user-attachments/assets/455dbded-296f-4bf1-b66f-2427a50bf217" width="700">
</p>

# ğŸ§© Conclusions

## ğŸ“Œ General Remarks About The Project 

This project represents **a fully automated, end-to-end analytics solution** with dbt-controlled transformation, Python-based analytics, and AI-augmented reporting.

Firstly, the project highlights **dbt**â€™s strength as a **transformation framework**, enabling modular, tested, and transparent data pipelines. It demonstrates the complete transformation workflow â€” from staging and intermediate logic to analytical marts â€” emphasizing the â€œTâ€ in ELT. Note that **freshness** and **incremental models** were not required here for this static dataset, but remain essential for real-time or production-level dbt projects. 

Secondly, the **Python layer** builds on dbt outputs to perform complex analytics such as anomaly detection, KPI calculations, and AI-driven narrative generation. The **LLM** layer interprets validated metrics to generate executive-ready insights embedded into Power BI. This enables fast, actionable interpretations of the data whenever dashboards are refreshed.

This design demonstrates how **analytics engineering, reproducible data science, and responsible AI/LLM usage** can be combined to deliver trustworthy, decision-ready insights.

## ğŸ“Š Data-driven Insights About OLIST Dataset 

The OLIST dataset reflects substantial operational scale with **$15.42 million in total revenue** across **96,477 orders** from **93,357 unique customers**, supported by **2,970 sellers**.  

**Key Performance Indicators (KPIs) â€“ based only on delivered (completed) orders:**
- ğŸ’° **Average Order Value (AOV):** $159.86  
- ğŸ›’ **Average Basket Size:** 1.14 items  
- ğŸ’µ **Revenue per Customer:** $165.20  
- ğŸ“¦ **Orders per Customer:** 1.03  
- ğŸª **Orders per Seller:** 32.48  

These metrics indicate a high average transaction value but a **predominantly single-purchase customer base**, as shown by the average orders per customer of just 1.03. This suggests **heavy reliance on new customer acquisition rather than repeat business**.  

Additional insights confirm this trend:  
- **Cohort Retention** and **RFM Segmentation** (visualized in Power BI) reveal strong acquisition but weak retention:  
  - **Fewer than 1% of customers** make a repeat purchase after their first month  
  - Only **~12.5% of customers** qualify as loyal or champion segments  
  - Most revenue comes from potential loyalists  

Complete analytic summaries (JSON files) and AI-augmented reports with business recommendations (txt files) are available in [this folder](https://github.com/Seyyed-Reza-Mashhadi/OLIST_Project/blob/master/python/output).

<p align="center">
  <img src="https://github.com/user-attachments/assets/5456d22e-e1b8-4575-a434-2843d274b32d" width="800">
</p>











